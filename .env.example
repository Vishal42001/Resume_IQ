# VITE_OPENAI_API_KEY - Your OpenAI API key (for online mode)
VITE_OPENAI_API_KEY=your_openai_api_key_here

# VITE_OLLAMA_URL - URL for local Ollama server (for offline mode)
VITE_OLLAMA_URL=http://localhost:11434

# VITE_LOCAL_MODEL - Local model to use with Ollama
# Options: llama2, mistral, codellama, llama3, phi, gemma, etc.
VITE_LOCAL_MODEL=llama2
